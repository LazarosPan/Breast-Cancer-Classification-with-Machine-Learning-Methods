{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diploma thesis\n",
    "## Breast cancer classification using machine learning methods\n",
    "### Best algorithms\n",
    "\n",
    "> Lazaros Panitsidis<br />\n",
    "> Department of Production and Management Engineering <br />\n",
    "> International Hellenic University <br />\n",
    "> lazarospanitsidis@outlook.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization library  \n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#import warnings library\n",
    "import warnings\n",
    "# ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# some of them are not used in this file\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFE, RFECV , mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, cross_val_score , GridSearchCV , LeaveOneOut,KFold,RandomizedSearchCV,StratifiedKFold,HalvingGridSearchCV\n",
    "from skopt import BayesSearchCV # https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV , https://scikit-optimize.github.io/stable/auto_examples/bayesian-optimization.html\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score , make_scorer , classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline , Pipeline # https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from xgboost import XGBClassifier , plot_importance\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier , RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis , QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier , AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgbm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pygad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 424 cases in this dataset\n",
      "There are 30 features in this dataset\n",
      "There are 212 cases diagnosed as malignant tumor\n",
      "There are 212 cases diagnosed as benign tumor\n",
      "The percentage of malignant cases is: 50.00%\n"
     ]
    }
   ],
   "source": [
    "dataWISC = pd.read_csv('dataWisc.csv')\n",
    "dataWISC.drop([\"id\", \"Unnamed: 32\"], axis = 1, inplace = True)\n",
    "\n",
    "# Undersampling function\n",
    "def make_undersample(_df, column):\n",
    "  dfs_r = {}\n",
    "  dfs_c = {}\n",
    "  smaller = 1e1000\n",
    "  ignore = \"\"\n",
    "  for c in _df[column].unique():\n",
    "    dfs_c[c] = _df[_df[column] == c]\n",
    "    if dfs_c[c].shape[0] < smaller:\n",
    "      smaller = dfs_c[c].shape[0]\n",
    "      ignore = c\n",
    "\n",
    "  for c in dfs_c:\n",
    "    if c == ignore:\n",
    "      continue\n",
    "    dfs_r[c] = resample(dfs_c[c], \n",
    "                        replace=False, # sample without replacement\n",
    "                        n_samples=smaller,\n",
    "                        random_state=0)\n",
    "  return pd.concat([dfs_r[c] for c in dfs_r] + [dfs_c[ignore]])\n",
    "\n",
    "dataWISC = make_undersample(dataWISC,'diagnosis')\n",
    "\n",
    "#Description of the dataset\n",
    "\n",
    "#how many cases are included in the dataset\n",
    "length = len(dataWISC)\n",
    "#how many features are in the dataset\n",
    "features = dataWISC.shape[1]-1 # - diagnosis\n",
    "\n",
    "# Number of malignant cases\n",
    "malignant = len(dataWISC[dataWISC['diagnosis']=='M'])\n",
    "\n",
    "#Number of benign cases\n",
    "benign = len(dataWISC[dataWISC['diagnosis']=='B'])\n",
    "\n",
    "#Rate of malignant tumors over all cases\n",
    "rate = (float(malignant)/(length))*100\n",
    "\n",
    "print (\"There are \"+ str(len(dataWISC))+\" cases in this dataset\")\n",
    "print (\"There are {}\".format(features)+\" features in this dataset\")\n",
    "print (\"There are {}\".format(malignant)+\" cases diagnosed as malignant tumor\")\n",
    "print (\"There are {}\".format(benign)+\" cases diagnosed as benign tumor\")\n",
    "print (\"The percentage of malignant cases is: {:.2f}%\".format(rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataWISC.diagnosis                          # M or B \n",
    "x = dataWISC.drop('diagnosis',axis = 1 )\n",
    "target_names=['Benign','Malignant']\n",
    "le= LabelEncoder()\n",
    "le.fit(y)\n",
    "y_le = le.transform(y)\n",
    "\n",
    "x_rf_xgb = x[['area_se','texture_mean','area_mean','smoothness_worst','concavity_worst','symmetry_worst','symmetry_se','concave points_se','concavity_se']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/loocv-for-evaluating-machine-learning-algorithms/#:~:text=Given%20the%20improved%20estimate%20of,biased%20estimates%20of%20model%20performance.\n",
    "# cv = LeaveOneOut()\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=13)\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "  originalclass.extend(y_true)\n",
    "  predictedclass.extend(y_pred)\n",
    "  #print(classification_report(y_true, y_pred, target_names=target_names)) \n",
    "  return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def print_best_params(grid_search):\n",
    "    print(\"\")\n",
    "    print(\"Best hyperparameters : \", grid_search.best_params_)\n",
    "    print(\"\")\n",
    "    print(\"Best estimator : \", grid_search.best_estimator_)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data train 90 % and test 10 %\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,stratify=y)\n",
    "\n",
    "scaler= StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "# PCA\n",
    "pca = PCA(n_components=7)\n",
    "pca.fit(x_train_scaled)\n",
    "x_train_pca = pca.transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n",
    "\n",
    "mlp=MLPClassifier(alpha=0.01, batch_size=40,\n",
    "                               hidden_layer_sizes=(14, 28),\n",
    "                               learning_rate='adaptive',\n",
    "                               learning_rate_init=0.01, max_iter=100,\n",
    "                               random_state=13, solver='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign      1.000     1.000     1.000        22\n",
      "   Malignant      1.000     1.000     1.000        21\n",
      "\n",
      "    accuracy                          1.000        43\n",
      "   macro avg      1.000     1.000     1.000        43\n",
      "weighted avg      1.000     1.000     1.000        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(x_train_pca,y_train)\n",
    "y_pred = mlp.predict(x_test_pca)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names,digits=3))\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "# sns.set(font_scale = 1.4)\n",
    "# sns.heatmap(cm,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NESTED CROSS VALIDATION MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_mlp =  Pipeline([('scaler', StandardScaler()),('pca',PCA(n_components=7)), ('mlp', MLPClassifier(random_state=13))])\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes' : [(14,28,)],\n",
    "    'mlp__activation' : ['tanh','relu'],\n",
    "    'mlp__solver' : ['sgd','adam'],\n",
    "    'mlp__alpha' : [0.01,0,2],\n",
    "    'mlp__batch_size' : [40,80,'auto'],\n",
    "    'mlp__learning_rate' : ['invscaling','adaptive'],\n",
    "    'mlp__learning_rate_init' : np.power(10, np.arange(-3, 0, dtype=float)),\n",
    "    'mlp__power_t' : [0.5],\n",
    "    'mlp__max_iter' : [50,100,200,500],\n",
    "    'mlp__shuffle' : [True],\n",
    "    'mlp__random_state' : [13]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_mlp, param_grid=param_grid, n_jobs=-1,cv=cv,verbose=0,scoring='f1_macro')\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "  \n",
    "# Îested - Cross validate\n",
    "score = cross_val_score(grid_search, x, y, scoring=make_scorer(classification_report_with_accuracy_score),cv=cv)\n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign      0.958     0.962     0.960       212\n",
      "   Malignant      0.962     0.958     0.960       212\n",
      "\n",
      "    accuracy                          0.960       424\n",
      "   macro avg      0.960     0.960     0.960       424\n",
      "weighted avg      0.960     0.960     0.960       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(originalclass, predictedclass, target_names=target_names, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NESTED CROSS VALIDATION KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign      0.959     0.981     0.970       212\n",
      "   Malignant      0.981     0.958     0.969       212\n",
      "\n",
      "    accuracy                          0.969       424\n",
      "   macro avg      0.970     0.969     0.969       424\n",
      "weighted avg      0.970     0.969     0.969       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_knn = Pipeline([('scaler', StandardScaler()),('pca',PCA(n_components=7)), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(2,10)),\n",
    "    'knn__weights': ['uniform','distance'],\n",
    "    'knn__algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n",
    "    'knn__leaf_size': [10,20,30,40,50],\n",
    "    'knn__p': [1,2],\n",
    "    'knn__metric': ['minkowski','manhattan','chebyshev']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf_knn, param_grid=param_grid, n_jobs=-1,cv=cv,verbose=0,scoring='f1_macro')\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "score = cross_val_score(grid_search, x, y, scoring=make_scorer(classification_report_with_accuracy_score),cv=cv)\n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 381\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 381\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 381\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 381\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 382\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 382\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 382\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 382\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 382\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "n_iterations: 3\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 3\n",
      "min_resources_: 40\n",
      "max_resources_: 382\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 1440\n",
      "n_resources: 40\n",
      "Fitting 10 folds for each of 1440 candidates, totalling 14400 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 480\n",
      "n_resources: 120\n",
      "Fitting 10 folds for each of 480 candidates, totalling 4800 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 160\n",
      "n_resources: 360\n",
      "Fitting 10 folds for each of 160 candidates, totalling 1600 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign      0.945     0.981     0.963       212\n",
      "   Malignant      0.980     0.943     0.962       212\n",
      "\n",
      "    accuracy                          0.962       424\n",
      "   macro avg      0.963     0.962     0.962       424\n",
      "weighted avg      0.963     0.962     0.962       424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_knn = Pipeline([('scaler', StandardScaler()),('pca',PCA(n_components=7)), ('knn', KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': list(range(2,10)),\n",
    "    'knn__weights': ['uniform','distance'],\n",
    "    'knn__algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n",
    "    'knn__leaf_size': [10,20,30,40,50],\n",
    "    'knn__p': [1,2],\n",
    "    'knn__metric': ['minkowski','manhattan','chebyshev']\n",
    "}\n",
    "\n",
    "grid_search = HalvingGridSearchCV(clf_knn, param_grid=param_grid, n_jobs=-1,cv=cv,verbose=1,scoring='f1_macro')\n",
    "\n",
    "originalclass = []\n",
    "predictedclass = []\n",
    "\n",
    "score = cross_val_score(grid_search, x, y, scoring=make_scorer(classification_report_with_accuracy_score),cv=cv)\n",
    "print(classification_report(originalclass, predictedclass, target_names=target_names, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
